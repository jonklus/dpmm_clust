---
title: "Diagnostics for DPMM"
author: "Jonathan Klus"
date: "2024-10-31"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# load necessary functions
# source("./Multivariate_DPMM_unknownvar_DEE.R")
# source("./Multivariate_DPMM_nonconj_DEV.R")
# source("./Multivariate_DPMM_nonconj_UVV.R")
source("./posterior_helper_fxns.R")
source("./post_processing_inf.R")

# load R libraries
library(ggplot2)
library(mclust)
library(LaplacesDemon)
library(mvtnorm)
library(stringr)
library(gridExtra)
library(dplyr)
library(knitr) # kable
library(kableExtra) # use for complex tables http://haozhu233.github.io/kableExtra/awesome_table_in_pdf.pdf
library(xtable)
library(scatterplot3d)
library(genMCMCDiag)
```


# Simulation results

```{r, message=FALSE, warning=FALSE, echo=FALSE}

# load R libraries


######################## DEFINE HELPER FUNCTIONS################################
# running locally
# data_path = "//GENE.bst.rochester.edu/Projects/JKSTproj/BlueHive_Sim_Results/"

# running on server
data_path = "/projects/jklus/JKSTproj/BlueHive_Sim_Results/SummaryKMeansInit"

# dev_withSM = readRDS(paste0(data_path, "/MODSUM_conjDEV_3close_n30_withSM_sim_results_ENAR/sum_1.rds"))

# list file extensions
file_ext = list.dirs(data_path)

# for each extension, make a new element of a data table with simulation attributes
summary_table = data.frame(Model = NA, Scenario = NA, SM = NA, Tag = NA, n_obs = NA, dataset_no = NA,
                           ARI = NA, KL = NA, Time = NA, MAP_K = NA) # should add , SumTime = NA for mod summary compute time

for(ext_index in 2:length(file_ext)){ # skip first one, listing main directory
                                      # skip second one, Archive directory
  # list files
  file_list = list.files(path = file_ext[ext_index])
  if(length(file_list) > 0){
    
    temp_summary_table = data.frame(Model = NA, Scenario = NA, SM = NA, Tag = NA, n_obs = NA, dataset_no = NA,
                                    ARI = NA, KL = NA, Time = NA, MAP_K = NA) # should add , SumTime = NA for mod summary compute time
    # parse out attributes and save
    short_file_ext = stringr::str_split(string = file_ext[ext_index], pattern = "/MODSUM")[[1]][2]
    parsed_dirname = unlist(stringr::str_extract_all(string = file_ext[ext_index], pattern = "_[:alnum:]+"))
    temp_summary_table[1:length(file_list), "Model"] = stringr::str_remove(string = parsed_dirname[3], pattern = "_")
    temp_summary_table[1:length(file_list), "Scenario"] = stringr::str_remove(string = parsed_dirname[4], pattern = "_")
    temp_summary_table[1:length(file_list), "n_obs"] = stringr::str_remove(string = parsed_dirname[5], pattern = "_n")
    temp_summary_table[1:length(file_list), "SM"] = stringr::str_remove(string = parsed_dirname[6], pattern = "_")
    # temp_summary_table[1:length(file_list), "Tag"] = stringr::str_remove(string = parsed_dirname[length(parsed_dirname)], pattern = "_")
    temp_summary_table[, "dataset_no"] = as.numeric(stringr::str_remove_all(string = file_list, pattern = "sum_|.rds"))
    
    # loop through all files in directory
    sum_bydataset = t(sapply(X = 1:length(file_list), 
                             FUN = function(x){
                               mod_sum = readRDS(paste0(file_ext[ext_index], "/", file_list[x]))
                               c(mod_sum$mean_ARI, 
                                 mod_sum$kl_div, 
                                 as.numeric(mod_sum$fit_runtime),
                                as.numeric(names(mod_sum$k_freqtab)[which.max(as.numeric(mod_sum$k_freqtab))])
                                 )
                             }))
    
    temp_summary_table[, "ARI"] = sum_bydataset[,1]
    temp_summary_table[, "KL"] = sum_bydataset[,2]
    temp_summary_table[, "Time"] = sum_bydataset[,3]
    temp_summary_table[, "MAP_K"] = sum_bydataset[,4]
    summary_table = rbind(summary_table, temp_summary_table)
    
  }
  
}

summary_table = summary_table[-1,] # get rid of first row of NAs 
  #vdplyr::filter(Scenario == "5grp3d")

summary_table %>%
  # dplyr::filter(Tag == "ENAR") %>%
  dplyr::group_by(Model, Scenario, SM, n_obs) %>%
  dplyr::summarize(Count = n()) %>%
  tidyr::pivot_wider(names_from = c(Scenario, n_obs), values_from = Count) %>%
  # keep first 2 columns with model info, sort remaining cols with results by n
  dplyr::select(1,2, gtools::mixedorder(names(.)[3:length(names(.))])+2) %>%
  knitr::kable(caption = "Number of data sets completed")

# time
summary_table %>% 
  # dplyr::filter(Tag == "ENAR") %>%
  dplyr::group_by(Model, Scenario, SM, n_obs) %>%
  dplyr::summarize(Time = round(mean(Time),2)) %>%
  tidyr::pivot_wider(names_from = c(Scenario, n_obs), values_from = Time) %>%
  # keep first 2 columns with model info, sort remaining cols with results by n
  dplyr::select(1,2, gtools::mixedorder(names(.)[3:length(names(.))])+2) %>%
  knitr::kable(caption = "Average computation time")

summary_table %>% 
  # dplyr::filter(Tag == "ENAR") %>%
  dplyr::group_by(Model, Scenario, SM, n_obs) %>%
  dplyr::summarize(mean_ARI = round(mean(ARI),2)) %>%
  tidyr::pivot_wider(names_from = c(Scenario, n_obs), values_from = mean_ARI) %>%
  # keep first 2 columns with model info, sort remaining cols with results by n
  dplyr::select(1,2, gtools::mixedorder(names(.)[3:length(names(.))])+2) %>%
  knitr::kable(caption = "Adjusted RAND Index")

summary_table %>% 
  # dplyr::filter(Tag == "ENAR") %>%
  dplyr::group_by(Model, Scenario, SM, n_obs) %>%
  dplyr::summarize(KL = round(mean(KL),2)) %>%
  tidyr::pivot_wider(names_from = c(Scenario, n_obs), values_from = KL) %>%
  # keep first 2 columns with model info, sort remaining cols with results by n
  dplyr::select(1,2, gtools::mixedorder(names(.)[3:length(names(.))])+2) %>%
  knitr::kable(caption = "KL Divergence")

summary_table %>% 
  # dplyr::filter(Tag == "ENAR") %>%
  dplyr::group_by(Model, Scenario, SM, n_obs) %>%
  dplyr::summarize(MAP_K = median(MAP_K)) %>%
  tidyr::pivot_wider(names_from = c(Scenario, n_obs), values_from = MAP_K) %>%
  # keep first 2 columns with model info, sort remaining cols with results by n
  dplyr::select(1,2, gtools::mixedorder(names(.)[3:length(names(.))])+2) %>%
  knitr::kable(caption = "MAP(K)")
```

## Traceplots for well-separated case

### n = 30

```{r}
hamming_dist_mcmc <- function(adj_mat_list){
  
  # computes the hamming distance between subsequent n*n laplacian matrices arranged
  # in a list of length S MCMC iterations
  
  sapply(X = 2:length(adj_mat_list), 
         FUN = function(x){
           sum(abs(adj_mat_list[[x]] - adj_mat_list[[x-1]]))
         })
}

sim_diagnostic_sum <- function(data_path, sim_dir, runs_to_plot){
  # data_path is directory where all simulation results directories reside
  # sim_dir is directory holding RMD files from a specific simulation run
  # num_traceplots is how many of the simulations traceplots should be generated & printed
  # runs_to_plot is a numeric array of sim numbers to print sim-level traceplots and diagnostics
  
  num_traceplots = length(runs_to_plot)

  result_wd = paste0(data_path, "/", sim_dir)
  result_file = list.files(result_wd)
  diagnostic_sum = data.frame(KLD = NA, ARI = NA, MAP_K = NA)
  
  if(num_traceplots > length(result_file)){
    stop(paste0("Only ", length(result_file), "sims available. Choose a smaller number
                of traceplots to print"))
  }
  
  for(i in 1:length(result_file)){
    
  output = readRDS(paste0(result_wd, "/", result_file[i]))
  run_no = as.numeric(stringr::str_extract(string = result_file[i], pattern = "[:digit:]+"))
  
  if(i == 1){
    output$settings # print priors, etc
  }
  
  # dim(output$group_assign)
  diagnostic_sum[i,"ARI"] = output$mean_ARI
  diagnostic_sum[i,"KLD"] = output$kl_div
  diagnostic_sum[i,"MAP_K"] = as.numeric(names(output$k_freqtab)[which.max(as.numeric(output$k_freqtab))])
  
    if(run_no %in% runs_to_plot){
      
        par(mfrow=c(1,2))
        # traceplot of K
        iter_k = sapply(X = 1:nrow(output$group_assign), 
                    FUN = function(x){
                      length(unique(output$group_assign[x,]))
                    })
        
        plot(x = 1:length(iter_k), y = iter_k, type = "l", xlab = "iter", ylab = "K",
              main = paste0("(#", 
                           stringr::str_extract(string = result_file[i], 
                                                pattern = "[:digit:]+"), 
                            ") ", "Traceplot of K"))
        
        # traceplot of sigma2 (for DEE only)
        sigma2_vec = output$var_list_by_k_stephens[[1]][,1]
        plot(x = 1:length(sigma2_vec), y = log(sigma2_vec), 
             type = "l", xlab = "iter", ylab = "log(sigma2)",
             main = paste0("(#", 
                           stringr::str_extract(string = result_file[i], 
                                                pattern = "[:digit:]+"), 
                           ") ", "Traceplot of sigma2"))
        abline(h = output$truth$sigma2, col = "blue")
  
        
        # Luke diagnostics
        # save each to object and use gridarrange??
        adjmat_list = list(get_adjmat_groupassign(group_assign = output$group_assign))
        true_ref = get_adjmat_groupassign(group_assign = matrix(output$truth$assign_true, nrow=1))

        # random reference
        d1 = genMCMCDiag::genDiagnostic(mhDraws = adjmat_list, method = "lanfear", 
                                   distance = hammingDist,
                                   diagnostics = "traceplot")
        p1 = ggplot2::ggplot(mapping = aes(x = d1$transformedDraws[1][[1]]$t,
                                           y = d1$transformedDraws[1][[1]]$val)) +
              ggplot2::geom_line() +
              ggplot2::theme_classic() +
              ggplot2::ylab("Hamming dist") +
              ggplot2::xlab("iter") +
              ggplot2::ggtitle("genMCMCdiag random lanfear ref") 
              # ggplot2::xlim(0, length(d1$transformedDraws[1][[1]]$t))+
              # ggplot2::scale_x_continuous(limits = c(0, length(d1$transformedDraws[1][[1]]$t)))
        
        # identity matrix reference
        d2 = genMCMCDiag::genDiagnostic(mhDraws = adjmat_list, method = "lanfear", 
                                   distance = hammingDist,
                                   diagnostics = "traceplot", 
                                   reference = diag(x = 1, nrow = nrow(adjmat_list[[1]][[1]])))
        p2 = ggplot2::ggplot(mapping = aes(x = d2$transformedDraws[1][[1]]$t,
                                           y = d2$transformedDraws[1][[1]]$val)) +
              ggplot2::geom_line() +
              ggplot2::theme_classic() +
              ggplot2::ylab("Hamming dist") +
              ggplot2::xlab("iter") +
              ggplot2::ggtitle("genMCMCdiag diag lanfear ref") 
              # ggplot2::xlim(0, length(d2$transformedDraws[1][[1]]$t))+
              # ggplot2::scale_x_continuous(limits = c(0, length(d2$transformedDraws[1][[1]]$t)))
        
        # true reference
        d3 = genMCMCDiag::genDiagnostic(mhDraws = adjmat_list, method = "lanfear", 
                                   distance = hammingDist,
                                   diagnostics = "traceplot", 
                                   reference = true_ref[[1]])
        p3 = ggplot2::ggplot(mapping = aes(x = d3$transformedDraws[1][[1]]$t,
                                           y = d3$transformedDraws[1][[1]]$val)) +
              ggplot2::geom_line() +
              ggplot2::theme_classic() +
              ggplot2::ylab("Hamming dist") +
              ggplot2::xlab("iter") +
              ggplot2::ggtitle("genMCMCdiag true lanfear ref") 
              # ggplot2::xlim(0, length(d3$transformedDraws[1][[1]]$t))+
              # ggplot2::scale_x_continuous(limits = c(0, length(d3$transformedDraws[1][[1]]$t)))
        
        # try doing hamming distance from iteration i to i+1
        hamming_diff = hamming_dist_mcmc(adj_mat_list = adjmat_list[[1]])
        p4 = ggplot2::ggplot(mapping = aes(x=1:length(hamming_diff), y = hamming_diff)) +
          ggplot2::geom_line() +
          ggplot2::theme_classic() +
          ggplot2::ylab("Hamming dist") +
          ggplot2::xlab("iter") +
          ggplot2::ggtitle("Hamming dist b/w iters") 
          # ggplot2::xlim(0, length(hamming_diff)) +
          # ggplot2::scale_x_continuous(limits = c(0, length(hamming_diff)))
        
        print(ggpubr::ggarrange(p1, p2, p3, p4, ncol = 2, nrow = 2))

      
    }

  }

  par(mfrow=c(2,3))
  hist(x = diagnostic_sum$KLD, main = "KLD", xlab = "KLD")
  hist(x = diagnostic_sum$ARI, main = "ARI", xlab = "ARI")
  hist(x = diagnostic_sum$MAP_K, main = "MAP_K", xlab = "MAP_K")
  
  plot(x = diagnostic_sum$KLD, y = diagnostic_sum$ARI, 
       xlab = "KLD", ylab = "ARI", 
       main = "KLD vs. ARI")
       # xlim = c(0,max(diagnostic_sum$KLD)+0.1), ylim = c(0,1))
  
  plot(x = diagnostic_sum$MAP_K, y = diagnostic_sum$ARI, 
       xlab = "MAP_K", ylab = "ARI", 
       main = "MAP_K vs. ARI") 
       # ylim = c(0,1))
  
  plot(x = diagnostic_sum$MAP_K, y = diagnostic_sum$KLD, 
       xlab = "MAP_K", ylab = "KLD", 
       main = "MAP_K vs. KLD")
       # ylim = c(0,max(diagnostic_sum$KLD)+0.1))
  
  
  return(diagnostic_sum)
  
}

data_path = "/projects/jklus/JKSTproj/BlueHive_Sim_Results/SummaryKMeansInit"
sim_dir = "MODSUM_conjDEE_3wellsep_n30_noSM_sim_results_2024_10_31"  

sum1 = sim_diagnostic_sum(data_path = data_path, 
                          sim_dir = sim_dir, 
                          runs_to_plot = c(1,10,100,11,12))

```

### n = 100

```{r}
sim_dir = "MODSUM_conjDEE_3wellsep_n100_noSM_sim_results_2024_10_31"  

sum1 = sim_diagnostic_sum(data_path = data_path, 
                          sim_dir = sim_dir, 
                          runs_to_plot = c(1,10,100,11,12))

# print some examples of K, var, and group assign when spikes or rapid changes
# occur, and when sampler gets stuck -- you have this info in the summary output
```

### n=30 with split/merge

```{r}
sim_dir = "MODSUM_conjDEE_3wellsep_n20_withSM_sim_results_2024_10_31"  

sum1 = sim_diagnostic_sum(data_path = data_path, 
                          sim_dir = sim_dir, 
                          runs_to_plot = c(1,10,100,11,12))


# print some examples of K, var, and group assign when spikes or rapid changes
# occur, and when sampler gets stuck -- you have this info in the summary output
```

### n=100 with split/merge

```{r}
sim_dir = "MODSUM_conjDEE_3wellsep_n100_withSM_sim_results_2024_10_31"  

sum1 = sim_diagnostic_sum(data_path = data_path, 
                          sim_dir = sim_dir, 
                          runs_to_plot = c(1,10,100,11,12))


# print some examples of K, var, and group assign when spikes or rapid changes
# occur, and when sampler gets stuck -- you have this info in the summary output
```