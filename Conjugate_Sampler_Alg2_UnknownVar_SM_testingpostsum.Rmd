---
title: "Conjugate Sampler - Testing Posterior Summaries"
author: "Jonathan Klus"
date: "2024-02-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load necessary functions
source("./Multivariate_DPMM_unknownvar_DEV.R")
source("./Multivariate_DPMM_unknownvar_DEE.R")
source("./Multivariate_DPMM_unknownvar_UVV.R")
source("./posterior_helper_fxns.R")
source("./post_processing_inf.R")

# load R libraries
library(ggplot2)
library(gridExtra)
library(plotly)
library(label.switching)
library(LaplacesDemon)
library(parallel)
library(stringr)
```

## Sampler Examples

### 2D Example - well separated

Mixture of 3 multivariate normal densities all with diagonal variance structure
and $\sigma^2 = 10$. The true means are $(-20,20)$, $(20,-20)$, and $(0,0)$, and
$\sum_{j}n_j = 30$.

```{r, echo=FALSE}
################## simulate data ##############################################

set.seed(516)
nreps = 10
seeds = sample(x = 1:10^4, size = nreps, replace = FALSE)

w = c(0.4, 0.3, 0.3)
means = list(
  c(-20, 20),
  c(20, -20),
  c(0, 0)
)

var = diag(10, length(means[[1]])) # variances known, diagonal, and equal

yreps = lapply(X = 1:nreps, 
           FUN = function(x){
             set.seed(seeds[x])
             assign = sample(x = 1:length(means), size = 30, replace = TRUE, prob = w)
             y = lapply(X = assign,
                        FUN = function(x){
                        t(mvtnorm::rmvnorm(n = 1, mean = means[[x]], sigma = var))
                          })
             return(list(y = y, assign = assign))
           })

# make a grid of plots
pltlist = list()
for(rep in 1:nreps){

  y_matrix = matrix(data = unlist(yreps[[rep]]$y), ncol = 2, byrow = TRUE)
  assign = yreps[[rep]]$assign

  data = data.frame(
    assign = assign,
    y1 = y_matrix[,1],
    y2 = y_matrix[,2]
  )

  p = ggplot(data = data, aes(x = y1, y = y2)) + #, label = rownames(data))) +
    geom_point(color = assign, size = 0.75) +
    #geom_text(size = 3, hjust = 0, nudge_x = 0.5, color = assign) +
    # geom_text(size = 3, color = assign) +
    theme_classic()

  pltlist[[rep]] = p
}

do.call(grid.arrange, pltlist)#, top = "Simulated 2D Data and True Group Assignments")

# drop params used to generate data, except for var which is assumed known
mu_true = means
var_true = var
# yreps # 2nd element is assign
rm(w, means)
```

#### DEE sampler

##### without split-merge step

```{r}
n_cores = max(parallel::detectCores()-2, 2)
sim_results_DEE_no_sm = readRDS(file = "../MCMC_Runs/conjDEEsamp_minisimstudy_noSM_2024_01_16.rds")

DEE_no_sm_sum = lapply(X = 1:length(sim_results_DEE_no_sm),
                         # mc.cores = n_cores,
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_DEE_no_sm, 
                             dataset_ind = x, 
                             print_k_sum = TRUE, 
                             # print_phi_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, equal_var = TRUE,
                             calc_KL = TRUE, mu_true = mu_true, 
                             var_true = var_true, assign_true = yreps[[x]]$assign)
                           })

# extract KL divergence and summarize
kld_DEE_no_sm_sum = sapply(X = 1:length(DEE_no_sm_sum), 
                           FUN = function(x){
                             DEE_no_sm_sum[[x]]$kl_div
                             })
print(kld_DEE_no_sm_sum)
mean(kld_DEE_no_sm_sum)
```

#### with split merge step

```{r}
sim_results_DEE_with_sm = readRDS(file = "../MCMC_Runs/conjDEEsamp_minisimstudy_withSM_2024_02_05.rds")

DEE_with_sm_sum = lapply(X = 1:length(sim_results_DEE_with_sm), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_DEE_with_sm, 
                             dataset_ind = x, 
                             print_k_sum = TRUE, 
                             # print_phi_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, equal_var = TRUE,
                             calc_KL = TRUE, mu_true = mu_true, 
                             var_true = var_true, assign_true = yreps[[x]]$assign)
                           })


# extract KL divergence and summarize
kld_DEE_with_sm_sum = sapply(X = 1:length(DEE_with_sm_sum), 
                           FUN = function(x){
                             DEE_with_sm_sum[[x]]$kl_div
                             })
print(kld_DEE_with_sm_sum)
mean(kld_DEE_with_sm_sum)
```

#### DEV sampler 

##### without split-merge step

```{r}
sim_results_DEV_no_sm = readRDS(file = "../MCMC_Runs/conjDEVsamp_minisimstudy_noSM_2024_01_16.rds")

DEV_no_sm_sum = lapply(X = 1:length(sim_results_DEV_no_sm), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_DEV_no_sm, 
                             dataset_ind = x, 
                             print_k_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = lapply(X = 1:length(mu_true), 
                                               FUN = function(x){var_true}))
                           # when equal_var=FALSE, need var_true to be same 
                           # length as mu_true
                           })


# extract KL divergence and summarize
kld_DEV_no_sm_sum = sapply(X = 1:length(DEV_no_sm_sum), 
                           FUN = function(x){
                             DEV_no_sm_sum[[x]]$kl_div
                             })
print(kld_DEV_no_sm_sum)
mean(kld_DEV_no_sm_sum)
```


##### with split-merge step

```{r}
sim_results_DEV_with_sm = readRDS(file = "../MCMC_Runs/conjDEVsamp_minisimstudy_withSM_2024_01_16.rds")

# got an error here with data set 1 that I haven't seen before -- need to investigate
# further
DEV_with_sm_sum = lapply(X = 1:length(sim_results_DEV_with_sm), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_DEV_with_sm, 
                             dataset_ind = x, 
                             print_k_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = lapply(X = 1:length(mu_true), 
                                               FUN = function(x){var_true}))
                           # when equal_var=FALSE, need var_true to be same 
                           # length as mu_true
                           })

# extract KL divergence and summarize
kld_DEV_with_sm_sum = sapply(X = 1:length(DEV_with_sm_sum), 
                           FUN = function(x){
                             DEV_with_sm_sum[[x]]$kl_div
                             })
print(kld_DEV_with_sm_sum)
mean(kld_DEV_with_sm_sum)

```

#### UVV sampler 

##### without split-merge step

```{r}
sim_results_UVV_no_sm = readRDS(file = "../MCMC_Runs/conjUVVsamp_minisimstudy_noSM_2024_01_16.rds")

UVV_no_sm_sum = lapply(X = 1:length(sim_results_UVV_no_sm), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_UVV_no_sm, 
                             dataset_ind = x, 
                             print_k_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = lapply(X = 1:length(mu_true), 
                                               FUN = function(x){var_true}))
                           })

# extract KL divergence and summarize
kld_UVV_no_sm_sum = sapply(X = 1:length(UVV_no_sm_sum), 
                           FUN = function(x){
                             UVV_no_sm_sum[[x]]$kl_div
                             })
print(kld_UVV_no_sm_sum)
mean(kld_UVV_no_sm_sum)

```


##### with split-merge step

```{r}
sim_results_UVV_with_sm = readRDS(file = "../MCMC_Runs/conjUVVsamp_minisimstudy_withSM_2024_01_16.rds")

# got an error here with data set 1 that I haven't seen before -- need to investigate
# further
UVV_with_sm_sum = lapply(X = 1:length(sim_results_UVV_with_sm), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_UVV_with_sm, 
                             dataset_ind = x, 
                             print_k_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = lapply(X = 1:length(mu_true), 
                                               FUN = function(x){var_true}))
                           })

# extract KL divergence and summarize
kld_UVV_with_sm_sum = sapply(X = 1:length(UVV_with_sm_sum), 
                           FUN = function(x){
                             UVV_with_sm_sum[[x]]$kl_div
                             })
print(kld_UVV_with_sm_sum)
mean(kld_UVV_with_sm_sum)
```

## 2D Example - close together

Mixture of 3 multivariate normal densities all with diagonal variance structure
and $\sigma^2 = 10$. The true means are $(10,10)$, $(0,-5)$, , $(12,-2)$, and $(0,10)$, and
$\sum_{j}n_j = 50$.

```{r, echo=FALSE}
################## simulate data ##############################################

set.seed(516)
nreps = 10
seeds = sample(x = 1:10^4, size = nreps, replace = FALSE)

w = c(.35, .25, .4)
means = list(
  #c(10, 10),
  c(0, -5),
  c(0, 10),
  c(12,2)
)

var = diag(9, length(means[[1]])) # variances known, diagonal, and equal

yreps = lapply(X = 1:nreps, 
           FUN = function(x){
             set.seed(seeds[x])
             assign = sample(x = 1:length(means), size = 30, replace = TRUE, prob = w)
             y = lapply(X = assign,
                        FUN = function(x){
                        t(mvtnorm::rmvnorm(n = 1, mean = means[[x]], sigma = var))
                          })
             return(list(y = y, assign = assign))
           })

# make a grid of plots
pltlist = list()
for(rep in 1:nreps){

  y_matrix = matrix(data = unlist(yreps[[rep]]$y), ncol = 2, byrow = TRUE)
  assign = yreps[[rep]]$assign

  data = data.frame(
    assign = assign,
    y1 = y_matrix[,1],
    y2 = y_matrix[,2]
  )

  p = ggplot(data = data, aes(x = y1, y = y2)) + #, label = rownames(data))) +
    geom_point(color = assign, size = 0.75) +
    #geom_text(size = 3, hjust = 0, nudge_x = 0.5, color = assign) +
    # geom_text(size = 3, color = assign) +
    theme_classic()

  pltlist[[rep]] = p
}

do.call(grid.arrange, pltlist)#, top = "Simulated 2D Data and True Group Assignments")

# drop params used to generate data, except for var which is assumed known
mu_true = means
var_true = var
# yreps # 2nd element is assign
rm(w, means)
```
#### DEE sampler

##### without split-merge step

```{r}
# n_cores = max(parallel::detectCores()-2, 2)
sim_results_DEE_no_sm_close = readRDS(file = "../MCMC_Runs/conjDEEsamp_minisimstudy_close_noSM_2024_01_16.rds")

DEE_no_sm_sum_close = lapply(X = 1:length(sim_results_DEE_no_sm_close),
                         # mc.cores = n_cores,
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_DEE_no_sm_close, 
                             dataset_ind = x, 
                             print_k_sum = TRUE, 
                             # print_phi_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, equal_var = TRUE, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = var_true)
                           })

# extract KL divergence and summarize
kld_DEE_no_sm_sum_close = sapply(X = 1:length(DEE_no_sm_sum_close), 
                           FUN = function(x){
                             DEE_no_sm_sum_close[[x]]$kl_div
                             })
print(kld_DEE_no_sm_sum_close)
mean(kld_DEE_no_sm_sum_close)
```

##### with split-merge step

```{r}

# n_iter = 5000
# use_cores = min(parallel::detectCores(), nreps)
# sim_results_DEE_with_sm_close = parallel::mclapply(X = 1:10, mc.cores = use_cores,
#       FUN = function(x){MVN_CRP_sampler_DEE(
#         S = n_iter, seed = seeds[x], y = yreps[[x]]$y,
#         alpha = 1, r = 10, g = 1, h = 50,
#         sigma_hyperprior = FALSE, fix_r = FALSE,
#         mu0 = matrix(round((colMeans(matrix(unlist(yreps[[x]]$y), ncol = 2))),0), ncol = 1),
#         a = 1, b = 50,
#         k_init = 1, diag_weights = FALSE,
#         verbose = FALSE, split_merge = TRUE
#         )}
#       )
# 
# datafile_name = paste0("../MCMC_Runs/conjDEEsamp_minisimstudy_close_withSM_",
#                        stringr::str_replace_all(Sys.Date(), pattern = "-", replacement = "_"), ".rds")
# saveRDS(object = sim_results_DEE_with_sm_close, file = datafile_name)

sim_results_DEE_with_sm_close = readRDS(file = "../MCMC_Runs/conjDEEsamp_minisimstudy_close_withSM_2024_02_08.rds")

DEE_with_sm_sum_close = lapply(X = 1:length(sim_results_DEE_with_sm_close),
                         # mc.cores = n_cores,
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_DEE_with_sm_close, 
                             dataset_ind = x, 
                             print_k_sum = TRUE, 
                             # print_phi_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, equal_var = TRUE, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = var_true)
                           })

# extract KL divergence and summarize
kld_DEE_with_sm_sum_close = sapply(X = 1:length(DEE_with_sm_sum_close), 
                           FUN = function(x){
                             DEE_with_sm_sum_close[[x]]$kl_div
                             })
print(kld_DEE_with_sm_sum_close)
mean(kld_DEE_with_sm_sum_close)
```

#### DEV sampler 

##### without split-merge step

```{r}

n_iter = 5000
use_cores = min(parallel::detectCores(), nreps)
# sim_results_DEV_no_sm_close = parallel::mclapply(X = 1:10, mc.cores = use_cores,
#       FUN = function(x){MVN_CRP_sampler_DEV(
#         S = n_iter, seed = seeds[x], y = yreps[[x]]$y,
#         alpha = 1, r = 10, g = 1, h = 50,
#         sigma_hyperprior = FALSE, fix_r = FALSE,
#         mu0 = matrix(round((colMeans(matrix(unlist(yreps[[x]]$y), ncol = 2))),0), ncol = 1),
#         a = 1, b = 50,
#         k_init = 1, diag_weights = FALSE,
#         verbose = FALSE, split_merge = FALSE
#         )}
#       )

x=10
sim_results_DEV_no_sm_close_10 = MVN_CRP_sampler_DEV(
        S = n_iter, seed = seeds[x], y = yreps[[x]]$y,
        alpha = 1, r = 10, g = 1, h = 50,
        sigma_hyperprior = FALSE, fix_r = FALSE,
        mu0 = matrix(round((colMeans(matrix(unlist(yreps[[x]]$y), ncol = 2))),0), ncol = 1),
        a = 1, b = 50,
        k_init = 1, diag_weights = FALSE,
        verbose = FALSE, split_merge = FALSE
      )

datafile_name = paste0("../MCMC_Runs/conjDEVsamp_minisimstudy_close_noSM_no10_",
                       stringr::str_replace_all(Sys.Date(), pattern = "-", replacement = "_"), ".rds")
saveRDS(object = sim_results_DEV_no_sm_close_10, file = datafile_name)
# 
# datafile_name = paste0("../MCMC_Runs/conjDEVsamp_minisimstudy_close_noSM_",
#                        stringr::str_replace_all(Sys.Date(), pattern = "-", replacement = "_"), ".rds")
# saveRDS(object = sim_results_DEV_no_sm_close, file = datafile_name)

sim_results_DEV_no_sm_close = readRDS(file = "../MCMC_Runs/conjDEVsamp_minisimstudy_close_noSM_2024_02_08.rds")

DEV_no_sm_sum_close = lapply(X = 1:9, #1:length(sim_results_DEV_no_sm_close), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_DEV_no_sm_close, 
                             dataset_ind = x, 
                             print_k_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = lapply(X = 1:length(mu_true), 
                                               FUN = function(x){var_true}))
                           # when equal_var=FALSE, need var_true to be same 
                           # length as mu_true
                           })
                     
# extract KL divergence and summarize
kld_DEV_no_sm_sum_close = sapply(X = 1:length(DEV_no_sm_sum_close), 
                           FUN = function(x){
                             DEV_no_sm_sum_close[[x]]$kl_div
                             })
print(kld_DEV_no_sm_sum_close)
mean(kld_DEV_no_sm_sum_close)

output = list(1,2,3,4,5,6,7,8,9,sim_results_DEV_no_sm_close_10)
dataset_ind = 10
print_phi_sum = FALSE
print_k_sum = TRUE
make_traceplot = TRUE
burn_in = 1000
t_hold = 100
num_dims = 2
calc_KL = TRUE
mu_true = mu_true
var_true = lapply(X = 1:length(mu_true), FUN = function(x){var_true})
assign_true = yreps[[dataset_ind]]$assign
equal_var = FALSE

  # output is the list of results from the DPMM simulation study function
  # dataset is a numeric argument to summarize a specific result in the output, the desired index
  # sum_all is a logical argument to provide a summary of all data sets --- NOT CURRENTLY IMPLEMENTED
  # print_k_sum is a logical, if TRUE print summary of no groups found
  # print_phi_sum is a logical, if TRUE print summary of estimated model parameters
  # burn_in is # of burn in iterations to discard
  # t_hold is the threshold # of iterations for a given k in order to report results
  # num_dims is the dimensionality of the problem (i.e. a bivariate normal is dim 2)
  # mu_true and var_true are list arguments with the true values of the model parameters
  # from a simulation study used to calculate the KL divergence
  # equal_var is a logical argument for whether the equal variance assumption was made
  # in the model. The function will then expect a scalar variance instead of a var-covar matrix

  # show basic summary
  if(print_k_sum == TRUE){
    cat("\n Frequency of MCMC iterations finding K groups:")
    print(table(output[[dataset_ind]]$k))

    cat("\n Percentage of MCMC iterations finding K groups:")
    print(round((table(output[[dataset_ind]]$k)/sum(table(output[[dataset_ind]]$k)))*100,1))

    cat("\n *Note that above frequency summaries of MCMC iterations were made before burn-in or thresholds were applied.
          All inference on phi will be made after accounting for burn-in and thresholding. \n")
  }

  # filter by number of iterations for each k and address label switching
    prob_list_by_k = get_probs_by_k(probs = output[[dataset_ind]]$group_probs,
                                    n_groups = output[[dataset_ind]]$k,
                                    burn_in = burn_in,
                                    iter_threshold = t_hold)
    group_assign_list_by_k = get_assign_by_k(assign = output[[dataset_ind]]$group_assign,
                                             n_groups = output[[dataset_ind]]$k,
                                             burn_in = burn_in,
                                             iter_threshold = t_hold)

    # correct label switching
    stephens_result = get_stephens_result(group_assign_list_by_k = group_assign_list_by_k,
                                          prob_list_by_k = prob_list_by_k$prob_list)

    # summarize means & variances
    mean_list_by_k_stephens = list_params_by_k(draws = output[[dataset_ind]]$means,
                                               k_vec = output[[dataset_ind]]$k,
                                               # burn_in = burn_in,
                                               # iter_threshold = thold,
                                               iter_list = prob_list_by_k$iter_list,
                                               relabel = TRUE,
                                               permutation = stephens_result,
                                               param_type = "Mean")

    var_list_by_k_stephens = list_params_by_k(draws = output[[dataset_ind]]$vars,
                                              iter_list = prob_list_by_k$iter_list,
                                              k_vec = output[[dataset_ind]]$k,
                                              relabel = TRUE, equal_var = equal_var,
                                              permutation = stephens_result,
                                              param_type = "Var")

    # compute KL divergence
    group_assign_list_by_k_corr = correct_group_assign(
      group_assign_list_by_k = group_assign_list_by_k,
      stephens_result = stephens_result)

    if(calc_KL == TRUE){

      kl_res = calc_KL_diverg(y = output[[dataset_ind]]$data,
                              mu_est = mean_list_by_k_stephens,
                              Sigma_est = var_list_by_k_stephens,
                              group_assign = group_assign_list_by_k_corr,
                              true_assign = assign_true,
                              mu_true = mu_true,
                              Sigma_true = var_true,
                              equal_var_assump = equal_var)
      # py is truth, px is estimate
      kl_div = kl_res$sum.KLD.py.px # how far is estimate px from truth py

    }

    mean_summary = vector(mode = "list", length = length(mean_list_by_k_stephens))
    var_summary = vector(mode = "list", length = length(mean_list_by_k_stephens))
    for(k in 1:length(mean_list_by_k_stephens)){

      # make mean summary table
      mean_summary[[k]] = make_postsum(mcmc_df = mean_list_by_k_stephens[[k]], digits = 2)

      # make variance summary table
      var_summary[[k]] = make_postsum(mcmc_df = var_list_by_k_stephens[[k]], digits = 2)

      k_i = ncol(var_list_by_k_stephens[[k]])
      if(print_phi_sum == TRUE){
        # give summary of counts after thresholding
        cat("\n K =", k_i, " n_k =", nrow(mean_list_by_k_stephens[[k]]), "after burn-in and thresholding\n")
        print(mean_summary[[k]])
        print(var_summary[[k]])
      }

      if(make_traceplot == TRUE){
        for(dim_i in 1:num_dims){
          make_traceplot(param_list_by_k = mean_list_by_k_stephens,
                         k = k_i,
                         component_no = dim_i,
                         p= num_dims,
                         # title_note = cat("K=", k_i),
                         param_type = "Mean")
        }
      }
    }

    # KL divergence for entire model --- across all k
    if(print_k_sum == TRUE){
      cat("\n KL Divergence: KL(p_est||p_true)=", round(kl_div, 3), "\n")
    }

```


##### with split-merge step

```{r}

# sim_results_DEV_with_sm_close = parallel::mclapply(X = 1:10, mc.cores = use_cores,
#       FUN = function(x){MVN_CRP_sampler_DEV(
#         S = n_iter, seed = seeds[x], y = yreps[[x]]$y,
#         alpha = 1, r = 10, g = 1, h = 50,
#         sigma_hyperprior = FALSE, fix_r = FALSE,
#         mu0 = matrix(round((colMeans(matrix(unlist(yreps[[x]]$y), ncol = 2))),0), ncol = 1),
#         a = 1, b = 50,
#         k_init = 1, diag_weights = FALSE,
#         verbose = FALSE, split_merge = TRUE, sm_iter = 10
#         )}
#       )
# 
# datafile_name = paste0("../MCMC_Runs/conjDEVsamp_minisimstudy_close_withSM_",
#                        stringr::str_replace_all(Sys.Date(), pattern = "-", replacement = "_"), ".rds")
# saveRDS(object = sim_results_DEV_with_sm_close, file = datafile_name)
x=1
sim_results_DEV_with_sm_close_1 = MVN_CRP_sampler_DEV(
        S = n_iter, seed = seeds[x], y = yreps[[x]]$y,
        alpha = 1, r = 10, g = 1, h = 50,
        sigma_hyperprior = FALSE, fix_r = FALSE,
        mu0 = matrix(round((colMeans(matrix(unlist(yreps[[x]]$y), ncol = 2))),0), ncol = 1),
        a = 1, b = 50,
        k_init = 1, diag_weights = FALSE,
        verbose = FALSE, split_merge = FALSE
      )

datafile_name = paste0("../MCMC_Runs/conjDEVsamp_minisimstudy_close_noSM_no10_",
                       stringr::str_replace_all(Sys.Date(), pattern = "-", replacement = "_"), ".rds")
saveRDS(object = sim_results_DEV_no_sm_close_10, file = datafile_name)


sim_results_DEV_with_sm_close = readRDS(file = "../MCMC_Runs/conjDEVsamp_minisimstudy_close_withSM_2024_01_16.rds")

# got an error here with data set 1 that I haven't seen before -- need to investigate
# further
DEV_with_sm_sum_close = lapply(X = 2:length(sim_results_DEV_with_sm_close), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_DEV_with_sm_close, 
                             dataset_ind = x, 
                             print_k_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = lapply(X = 1:length(mu_true), 
                                               FUN = function(x){var_true}))
                           # when equal_var=FALSE, need var_true to be same 
                           # length as mu_true
                           })


# extract KL divergence and summarize
kld_DEV_with_sm_sum_close = sapply(X = 1:length(DEV_with_sm_sum_close), 
                           FUN = function(x){
                             DEV_with_sm_sum_close[[x]]$kl_div
                             })
print(kld_DEV_with_sm_sum_close)
mean(kld_DEV_with_sm_sum_close)

```

#### UVV sampler 

##### without split-merge step

```{r}
sim_results_UVV_no_sm_close = readRDS(file = "../MCMC_Runs/conjUVVsamp_minisimstudy_close_noSM_2024_01_16.rds")

UVV_no_sm_sum_close = lapply(X = 1:length(sim_results_UVV_no_sm_close), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_UVV_no_sm_close, 
                             dataset_ind = x, 
                             print_k_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = lapply(X = 1:length(mu_true), 
                                               FUN = function(x){var_true}))
                           # when equal_var=FALSE, need var_true to be same 
                           # length as mu_true
                           })

# extract KL divergence and summarize
kld_UVV_no_sm_sum_close = sapply(X = 1:length(UVV_no_sm_sum_close), 
                           FUN = function(x){
                             UVV_no_sm_sum_close[[x]]$kl_div
                             })
print(kld_UVV_no_sm_sum_close)
mean(kld_UVV_no_sm_sum_close)

```


##### with split-merge step

```{r}
sim_results_UVV_with_sm_close = readRDS(file = "../MCMC_Runs/conjUVVsamp_minisimstudy_close_withSM_2024_01_16.rds")

# got an error here with data set 1 that I haven't seen before -- need to investigate
# further
UVV_with_sm_sum_close = lapply(X = 1:length(sim_results_UVV_with_sm_close), 
                         FUN = function(x){
                           cat("\n Dataset #", x)
                           dpmm_summary(output = sim_results_UVV_with_sm_close, 
                             dataset_ind = x, 
                             print_k_sum = TRUE,
                             make_traceplot = FALSE,
                             burn_in = 1000, t_hold = 100, 
                             num_dims = 2, calc_KL = TRUE, 
                             mu_true = mu_true, assign_true = yreps[[x]]$assign,
                             var_true = lapply(X = 1:length(mu_true), 
                                               FUN = function(x){var_true}))
                           # when equal_var=FALSE, need var_true to be same 
                           # length as mu_true
                           })

# extract KL divergence and summarize
kld_UVV_with_sm_sum_close = sapply(X = 1:length(UVV_with_sm_sum_close), 
                           FUN = function(x){
                             UVV_with_sm_sum_close[[x]]$kl_div
                             })
print(kld_UVV_with_sm_sum_close)
mean(kld_UVV_with_sm_sum_close)
```




## KL Divergence Summary

### Well-separated example

```{r}
kld_summary_sep = matrix(data = NA, nrow = 2, ncol = 3)
colnames(kld_summary_sep) = c("DEE", "DEV", "UVV")
row.names(kld_summary_sep) = c("no SM", "with SM")

kld_summary_sep[,"DEE"] = c(mean(kld_DEE_no_sm_sum), mean(kld_DEE_with_sm_sum))
kld_summary_sep[,"DEV"] = c(mean(kld_DEV_no_sm_sum), mean(kld_DEV_with_sm_sum))
kld_summary_sep[,"UVV"] = c(mean(kld_UVV_no_sm_sum), mean(kld_UVV_with_sm_sum))
kld_summary_sep
saveRDS(object = kld_summary_sep, file = "../MCMC_Runs/kld_summary_sep_02_08_2024.rds")
```

### Close together example

```{r}
kld_summary_close = matrix(data = NA, nrow = 2, ncol = 3)
colnames(kld_summary_close) = c("DEE", "DEV", "UVV")
row.names(kld_summary_close) = c("no SM", "with SM")

kld_summary_close[,"DEE"] = c(mean(kld_DEE_no_sm_sum_close), mean(kld_DEE_with_sm_sum_close))
kld_summary_close[,"DEV"] = c(NA, NA) # c(mean(kld_DEV_no_sm_sum_close), mean(kld_DEV_with_sm_sum_close))
kld_summary_close[,"UVV"] = c(mean(kld_UVV_no_sm_sum_close), mean(kld_UVV_with_sm_sum_close))
kld_summary_close
saveRDS(object = kld_summary_close, file = "../MCMC_Runs/kld_summary_close_02_08_2024.rds")
```